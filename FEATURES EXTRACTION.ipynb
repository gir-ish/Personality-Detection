{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6df1bca-9b05-4263-9598-530aea539cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\giris\\anaconda3\\envs\\tf\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\giris\\anaconda3\\envs\\tf\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551c469a-d6bb-49d3-8b3e-74b5a3a6ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c2da6-66b1-4b2b-af98-7813d82e54bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# video features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c5d4e-cb97-4098-bbf1-cf4fe106f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import av\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, VideoMAEModel\n",
    "import os\n",
    "import glob  \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    end_idx = np.random.randint(converted_len, seg_len)\n",
    "    start_idx = end_idx - converted_len\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices\n",
    "\n",
    "def extract_video_features(file_path, device):\n",
    "    container = av.open(file_path)\n",
    "    indices = sample_frame_indices(clip_len=16, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\n",
    "    video = read_video_pyav(container, indices)\n",
    "    \n",
    "    image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "    model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "    model.to(device)\n",
    "    \n",
    "    inputs = image_processor(list(video), return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    return file_path, features\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "video_folder = \"C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Video_Interview\"  # Change this to your folder path\n",
    "\n",
    "video_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
    "\n",
    "all_features = []\n",
    "file_names = []\n",
    "for file_path in video_files:\n",
    "    file_name, features = extract_video_features(file_path, device)\n",
    "    file_names.append(os.path.basename(file_name))  \n",
    "    all_features.append(features)\n",
    "\n",
    "features_df = pd.DataFrame(all_features)\n",
    "features_df['file_name'] = file_names \n",
    "features_csv_path = 'C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Video_Interview_features.csv' \n",
    "features_df.to_csv(features_csv_path, index=False)\n",
    "#video_folder = \"C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Video_Interview\"\n",
    "#features_csv_path = \"C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Video_Interview_features.csv\"\n",
    "print(f\"Features saved to {features_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5679bb-225d-4d03-8e6a-7bf10646bf8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# audio from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3d4c9-e53e-4dce-9cdb-56c8a3e56fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def extract_audio_ffmpeg(video_file_path, audio_file_path):\n",
    "    # Include the -y flag to automatically overwrite existing files\n",
    "    command = ['ffmpeg', '-y', '-i', video_file_path, '-q:a', '0', '-map', 'a', audio_file_path]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(f\"Successfully extracted audio to {audio_file_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing {video_file_path}: {e}\")\n",
    "\n",
    "def process_all_videos(video_folder_path, output_folder_path):\n",
    "   \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    for filename in os.listdir(video_folder_path):\n",
    "        if filename.endswith((\".mp4\", \".mkv\", \".avi\")): \n",
    "            video_file_path = os.path.join(video_folder_path, filename)\n",
    "            audio_filename = os.path.splitext(filename)[0] + \".mp3\"\n",
    "            audio_file_path = os.path.join(output_folder_path, audio_filename)\n",
    "            \n",
    "            extract_audio_ffmpeg(video_file_path, audio_file_path)\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file: {filename}\")\n",
    "\n",
    "video_folder_path = 'C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Video_Interview'\n",
    "output_folder_path = 'C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Extracted_Audio'\n",
    "process_all_videos(video_folder_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a41479-4598-483e-bf85-584c4fc24250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# XLSR FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17f0d9-6914-4176-85dd-1bcdc0697513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d4e25-b28f-4248-8e58-2af53aee428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_folder = 'C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Extracted_Audio'\n",
    "output_folder = 'C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Extracted_Audio_features'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "processed_files = [os.path.splitext(f)[0] for f in os.listdir(output_folder) if f.endswith('.csv')]\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".mp3\"):\n",
    "        audio_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        if os.path.splitext(filename)[0] in processed_files:\n",
    "            print(f\"Features for {filename} already extracted, skipping...\")\n",
    "            continue\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        if sample_rate != 16000:\n",
    "            resampler = Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "            waveform = resampler(waveform)\n",
    "            sample_rate = 16000  \n",
    "\n",
    "        inputs = feature_extractor(waveform.squeeze(), return_tensors=\"pt\", padding=\"longest\", sampling_rate=sample_rate)\n",
    "        with torch.no_grad():\n",
    "            features = model(**inputs).last_hidden_state\n",
    "\n",
    "        features_np = features.squeeze().detach().numpy()\n",
    "\n",
    "        df = pd.DataFrame(features_np)\n",
    "\n",
    "        csv_filename = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_features.csv\")\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "        print(f\"Features saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5e32a-26e4-4269-98ed-0464f257df9a",
   "metadata": {},
   "source": [
    "# vggish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0069bcd-1672-426a-9a55-3152cb563acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_hub import load  # Ensure TensorFlow Hub is installed: pip install tensorflow-hub\n",
    "\n",
    "# Load the VGGish model\n",
    "vggish_model = load('https://tfhub.dev/google/vggish/1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3589be-9f8d-49d4-909f-5c93dcca8403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_and_preprocess_audio(audio_path, target_sr=16000):\n",
    "    \"\"\"\n",
    "    Load and preprocess audio data from the given file path.\n",
    "    \n",
    "    Parameters:\n",
    "        audio_path (str): Path to the audio file.\n",
    "        target_sr (int): Target sampling rate for resampling the audio (default: 16000).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed audio data.\n",
    "    \"\"\"\n",
    "    audio_data, _ = librosa.load(audio_path, sr=target_sr, mono=True)\n",
    "    \n",
    "    \n",
    "    return audio_data\n",
    "\n",
    "def extract_vggish_features(audio_path):\n",
    "    \"\"\"\n",
    "    Extract VGGish features from the given audio file.\n",
    "    \n",
    "    Parameters:\n",
    "        audio_path (str): Path to the audio file.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: VGGish features.\n",
    "    \"\"\"\n",
    "    audio_data = load_and_preprocess_audio(audio_path)\n",
    "    embeddings = vggish_model(audio_data)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "features = extract_vggish_features('C:/Users/giris/Downloads/RESEARCH/Personality/personality_data/Extracted_Audio/wzewmMk_Nzv.mp3')\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef643c30-5667-4e71-8e74-366965d29f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(features, axis=0).reshape(1, -1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
